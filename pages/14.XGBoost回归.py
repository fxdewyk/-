
import streamlit as st
import pandas as pd
import xgboost as xgb
import numpy as np
import matplotlib.pyplot as plt
import shap
import joblib
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from xgboost.callback import TrainingCallback

st.set_page_config(page_title="ğŸ¯ XGBoost é«˜çº§å›å½’åˆ†æ", layout="wide")
st.title("ğŸ¯ XGBoost é«˜çº§å›å½’åˆ†æ")

# ==================== ä¿®å¤åçš„å›è°ƒç±» ====================
class StreamlitProgress(TrainingCallback):
    def __init__(self, total_rounds):
        self.total_rounds = total_rounds
        self.progress_bar = None
        self.status_text = None

    def before_training(self, model):
        self.progress_bar = st.progress(0.0)
        self.status_text = st.empty()
        return model

    def after_iteration(self, model, epoch, evals_log):
        current = epoch + 1
        progress = current / self.total_rounds
        self.progress_bar.progress(progress)
        self.status_text.text(f"è®­ç»ƒè¿›åº¦: {current}/{self.total_rounds} è½®")
        return False

    def after_training(self, model):
        self.progress_bar.empty()
        self.status_text.empty()
        return model

# ==================== æ•°æ®é¢„å¤„ç†æ¨¡å— ====================
def preprocess_data(df):
    with st.expander("ğŸ”§ æ•°æ®é¢„å¤„ç†è®¾ç½®", expanded=True):
        col1, col2 = st.columns(2)

        with col1:
            missing_strategy = st.selectbox(
                "ç¼ºå¤±å€¼å¤„ç†",
                ["åˆ é™¤ç¼ºå¤±è¡Œ", "æ•°å€¼åˆ—å¡«å……ä¸­ä½æ•°", "åˆ†ç±»åˆ—å¡«å……ä¼—æ•°"],
                index=1
            )

        with col2:
            scale_numeric = st.checkbox("æ ‡å‡†åŒ–æ•°å€¼ç‰¹å¾", True)
            encode_categorical = st.checkbox("ç¼–ç åˆ†ç±»ç‰¹å¾", True)

    if missing_strategy == "åˆ é™¤ç¼ºå¤±è¡Œ":
        df = df.dropna()

    return df, {
        'missing_strategy': missing_strategy,
        'scale_numeric': scale_numeric,
        'encode_categorical': encode_categorical
    }

# ==================== ä¸»ç¨‹åºæµç¨‹ ====================
uploaded_file = st.sidebar.file_uploader("ğŸ“‚ ä¸Šä¼ CSVæ–‡ä»¶", type=["csv"])

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    processed_df, preprocess_params = preprocess_data(df)

    with st.sidebar:
        st.markdown("## ğŸ¯ ç›®æ ‡å˜é‡è®¾ç½®")
        target_col = st.selectbox("é€‰æ‹©ç›®æ ‡åˆ—", processed_df.columns)

        st.markdown("## ğŸ“Š ç‰¹å¾é€‰æ‹©")
        feature_cols = st.multiselect(
            "é€‰æ‹©é¢„æµ‹ç‰¹å¾",
            [col for col in processed_df.columns if col != target_col]
        )

        st.markdown("## âš™ é«˜çº§å‚æ•°è®¾ç½®")
        with st.expander("æ¨¡å‹å‚æ•°"):
            params = {
                'max_depth': st.slider("æœ€å¤§æ·±åº¦", 1, 12, 6),
                'learning_rate': st.slider("å­¦ä¹ ç‡", 0.001, 0.5, 0.1, 0.005),
                'n_estimators': st.slider("æ ‘çš„æ•°é‡", 10, 2000, 500, 10),
                'gamma': st.slider("gamma", 0.0, 1.0, 0.0, 0.1),
                'subsample': st.slider("å­é‡‡æ ·ç‡", 0.1, 1.0, 1.0, 0.05)
            }

        with st.expander("è®­ç»ƒè®¾ç½®"):
            early_stop = st.number_input("æ—©åœè½®æ•°", 10, 100, 50)

    if feature_cols:
        # ==================== æ•°æ®é¢„å¤„ç†ç®¡é“ ====================
        numeric_features = processed_df[feature_cols].select_dtypes(include=np.number).columns.tolist()
        categorical_features = list(set(feature_cols) - set(numeric_features))

        numeric_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='median')),
            ('scaler', StandardScaler()) if preprocess_params['scale_numeric'] else ('passthrough', 'passthrough')
        ])

        categorical_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='most_frequent')),
            ('encoder', OneHotEncoder(handle_unknown='ignore')) if preprocess_params['encode_categorical'] else ('passthrough', 'passthrough')
        ])

        preprocessor = ColumnTransformer(
            transformers=[
                ('num', numeric_transformer, numeric_features),
                ('cat', categorical_transformer, categorical_features)
            ])

        # ==================== æ¨¡å‹è®­ç»ƒ ====================
        X = processed_df[feature_cols]
        y = processed_df[target_col]

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        dtrain = xgb.DMatrix(preprocessor.fit_transform(X_train), label=y_train)
        dtest = xgb.DMatrix(preprocessor.transform(X_test), label=y_test)

        # ä¿®å¤è¯„ä¼°ç»“æœå­˜å‚¨
        evals_result = {}  # åˆ›å»ºå­˜å‚¨è¯„ä¼°ç»“æœçš„å­—å…¸

        progress_callback = StreamlitProgress(params['n_estimators'])

        model = xgb.train(
            params,
            dtrain,
            num_boost_round=params['n_estimators'],
            early_stopping_rounds=early_stop,
            evals=[(dtest, "æµ‹è¯•é›†")],
            evals_result=evals_result,  # ä¼ å…¥å­˜å‚¨å­—å…¸
            callbacks=[progress_callback],
            verbose_eval=False
        )

        # ==================== æ¨¡å‹è¯„ä¼° ====================
        st.subheader("ğŸ“ˆ æ¨¡å‹è¯„ä¼°")
        y_pred = model.predict(dtest)

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("RMSE", f"{np.sqrt(mean_squared_error(y_test, y_pred)):.4f}")
        with col2:
            st.metric("RÂ² Score", f"{r2_score(y_test, y_pred):.4f}")
        with col3:
            st.metric("æœ€ä½³è¿­ä»£è½®æ¬¡", model.best_iteration)

        # ==================== å¯è§†åŒ–æ¨¡å— ====================
        tabs = st.tabs(["ğŸ“‰ é¢„æµ‹åˆ†æ", "ğŸ“Š ç‰¹å¾é‡è¦æ€§", "ğŸ” SHAPè§£é‡Š", "ğŸ“ˆ å­¦ä¹ æ›²çº¿"])

        with tabs[0]:
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))
            ax1.scatter(y_test, y_pred, alpha=0.6)
            ax1.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
            ax1.set_title("å®é™…å€¼ vs é¢„æµ‹å€¼")

            residuals = y_test - y_pred
            ax2.hist(residuals, bins=30)
            ax2.set_title("æ®‹å·®åˆ†å¸ƒ")
            st.pyplot(fig)

        with tabs[1]:
            fig, ax = plt.subplots(figsize=(10, 6))
            xgb.plot_importance(model, ax=ax)
            st.pyplot(fig)

        with tabs[2]:
            explainer = shap.TreeExplainer(model)
            shap_values = explainer(dtest)
            fig, ax = plt.subplots(figsize=(10, 6))
            shap.plots.bar(shap_values, max_display=10, show=False)
            st.pyplot(fig)

        with tabs[3]:
            # ä½¿ç”¨å­˜å‚¨çš„è¯„ä¼°ç»“æœ
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.plot(evals_result['æµ‹è¯•é›†']['rmse'], label='æµ‹è¯•é›†')  # ä»å­—å…¸è·å–æ•°æ®
            ax.set_xlabel('è¿­ä»£è½®æ¬¡')
            ax.set_ylabel('RMSE')
            ax.set_title('å­¦ä¹ æ›²çº¿')
            ax.legend()
            st.pyplot(fig)

        # ==================== æ¨¡å‹ä¿å­˜ ====================
        st.sidebar.markdown("## ğŸ’¾ æ¨¡å‹ç®¡ç†")
        if st.sidebar.button("ä¿å­˜å½“å‰æ¨¡å‹"):
            model.save_model('xgboost_model.json')
            joblib.dump(preprocessor, 'preprocessor.pkl')
            st.sidebar.success("æ¨¡å‹å·²ä¿å­˜ä¸º xgboost_model.json å’Œ preprocessor.pkl")

else:
    st.info("ğŸ“¥ è¯·ä¸Šä¼ CSVæ ¼å¼çš„æ•°æ®æ–‡ä»¶")
